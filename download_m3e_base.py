#!/usr/bin/env python3
"""
ä½¿ç”¨ModelScopeä¸‹è½½M3E-BaseåµŒå…¥æ¨¡å‹
ä¸“é—¨ä¸ºä¸­æ–‡ä¼˜åŒ–çš„åµŒå…¥æ¨¡å‹ï¼Œæ”¯æŒç¦»çº¿æ¨¡å¼ï¼Œé€‚åˆ16Gå†…å­˜ç¯å¢ƒ
æ¨¡å‹åœ°å€: https://modelscope.cn/models/AI-ModelScope/m3e-base
"""

import os
import sys
import time
from pathlib import Path

def download_m3e_model():
    """ä½¿ç”¨ModelScopeä¸‹è½½M3E-Baseæ¨¡å‹"""
    
    print("ğŸš€ å¼€å§‹ä¸‹è½½M3E-Baseæ¨¡å‹...")
    print("ğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
    print("   - åç§°: AI-ModelScope/m3e-base")
    print("   - åœ°å€: https://modelscope.cn/models/AI-ModelScope/m3e-base")
    print("   - å¤§å°: çº¦400MB")
    print("   - ç»´åº¦: 768ç»´")
    print("   - ç‰¹ç‚¹: ä¸“é—¨ä¸ºä¸­æ–‡ä¼˜åŒ–ï¼Œæ”¯æŒå¤šè¯­è¨€ï¼Œç¦»çº¿å‹å¥½")
    print("   - é€‚ç”¨: 16Gå†…å­˜ç¯å¢ƒï¼ŒRAGç³»ç»Ÿ")
    print()
    
    try:
        # å¯¼å…¥ModelScope
        from modelscope import snapshot_download
        
        # ç¡®ä¿modelsç›®å½•å­˜åœ¨
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        
        print("ğŸ“¥ æ­£åœ¨ä»ModelScopeä¸‹è½½M3E-Baseæ¨¡å‹...")
        print("â³ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        start_time = time.time()
        
        # ä½¿ç”¨ModelScopeä¸‹è½½æ¨¡å‹ - ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹ID
        model_dir = snapshot_download(
            model_id="AI-ModelScope/m3e-base",
            cache_dir="models",
            revision="master"
        )
        
        end_time = time.time()
        download_time = end_time - start_time
        
        print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_dir}")
        print(f"â±ï¸ è€—æ—¶: {download_time:.1f}ç§’")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if Path(model_dir).exists():
            total_size = sum(f.stat().st_size for f in Path(model_dir).rglob('*') if f.is_file())
            size_mb = total_size / 1024 / 1024
            print(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶å¤§å°: {size_mb:.1f}MB")
            
            # åˆ—å‡ºä¸»è¦æ¨¡å‹æ–‡ä»¶
            print("\nğŸ“ æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:")
            important_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json', 'vocab.txt']
            for file_path in Path(model_dir).iterdir():
                if file_path.is_file():
                    file_size = file_path.stat().st_size / 1024 / 1024
                    status = "ğŸ”‘" if file_path.name in important_files else "ğŸ“„"
                    print(f"   {status} {file_path.name}: {file_size:.1f}MB")
        
        print("\nğŸ‰ M3E-BaseåµŒå…¥æ¨¡å‹å®‰è£…å®Œæˆï¼")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥åœ¨RAGç³»ç»Ÿä¸­ä½¿ç”¨è¿™ä¸ªæ¨¡å‹äº†")
        
        return model_dir
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("3. å°è¯•æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        print("4. æ£€æŸ¥ModelScopeä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")
        return None

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        # å°è¯•ä½¿ç”¨sentence-transformersåŠ è½½
        try:
            from sentence_transformers import SentenceTransformer
            
            # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½
            model_paths = [
                "AI-ModelScope/m3e-base",  # ModelScopeè·¯å¾„
                "models/AI-ModelScope/m3e-base",  # æœ¬åœ°è·¯å¾„
            ]
            
            model = None
            for path in model_paths:
                try:
                    print(f"ğŸ”„ å°è¯•åŠ è½½è·¯å¾„: {path}")
                    model = SentenceTransformer(path)
                    print(f"âœ… æˆåŠŸä»è·¯å¾„åŠ è½½: {path}")
                    break
                except Exception as e:
                    print(f"âš ï¸ è·¯å¾„ {path} åŠ è½½å¤±è´¥: {e}")
                    continue
            
            if model is None:
                print("âŒ æ‰€æœ‰è·¯å¾„éƒ½åŠ è½½å¤±è´¥")
                return False
            
            # æµ‹è¯•ç¼–ç 
            test_texts = [
                "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­",
                "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
                "M3E-Baseæ˜¯ä¸€ä¸ªä¼˜ç§€çš„ä¸­æ–‡åµŒå…¥æ¨¡å‹",
                "RAGç³»ç»Ÿéœ€è¦é«˜è´¨é‡çš„åµŒå…¥å‘é‡"
            ]
            
            print("ğŸ” æ­£åœ¨æµ‹è¯•ç¼–ç åŠŸèƒ½...")
            embeddings = model.encode(test_texts)
            print(f"âœ… æ¨¡å‹ç¼–ç æµ‹è¯•æˆåŠŸï¼")
            print(f"   - ç»´åº¦: {embeddings.shape[1]}")
            print(f"   - è¾“å…¥æ–‡æœ¬æ•°é‡: {len(test_texts)}")
            print(f"   - åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
            
            # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
            from sklearn.metrics.pairwise import cosine_similarity
            similarity = cosine_similarity(embeddings[:2])
            print(f"   - ç¤ºä¾‹ç›¸ä¼¼åº¦: {similarity[0][1]:.4f}")
            
        except ImportError:
            print("âš ï¸ sentence-transformersæœªå®‰è£…ï¼Œè·³è¿‡æµ‹è¯•")
        except Exception as e:
            print(f"âš ï¸ sentence-transformersåŠ è½½å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def update_config():
    """æ›´æ–°é…ç½®æ–‡ä»¶ä»¥ä½¿ç”¨M3E-Baseæ¨¡å‹"""
    print("\nâš™ï¸ æ›´æ–°é…ç½®æ–‡ä»¶...")
    
    try:
        config_path = "src/config.py"
        
        # è¯»å–é…ç½®æ–‡ä»¶
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢æ¨¡å‹åç§°
        old_patterns = [
            'EMBEDDING_MODEL_NAME = "BAAI/bge-small-zh-v1.5"',
            'EMBEDDING_MODEL_NAME = "moka-ai/m3e-base"'
        ]
        
        new_value = 'EMBEDDING_MODEL_NAME = "AI-ModelScope/m3e-base"'
        
        new_content = content
        for pattern in old_patterns:
            if pattern in content:
                new_content = new_content.replace(pattern, new_value)
                break
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°ç°æœ‰é…ç½®ï¼Œæ·»åŠ æ³¨é‡Š
            print("âš ï¸ æœªæ‰¾åˆ°ç°æœ‰æ¨¡å‹é…ç½®ï¼Œè¯·æ‰‹åŠ¨æ›´æ–°")
            return False
        
        # å†™å›é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°ä¸ºä½¿ç”¨M3E-Baseæ¨¡å‹")
        print(f"âœ… æ–°é…ç½®: {new_value}")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ›´æ–°å¤±è´¥: {e}")
        return False

def test_rag_integration():
    """æµ‹è¯•RAGç³»ç»Ÿé›†æˆ"""
    print("\nğŸ” æµ‹è¯•RAGç³»ç»Ÿé›†æˆ...")
    
    try:
        # å¯¼å…¥RAGç³»ç»Ÿ
        sys.path.append("src")
        from rag_system import RAGSystem
        from config import Config
        
        # åˆ›å»ºé…ç½®
        config = Config()
        print(f"ğŸ“‹ å½“å‰é…ç½®çš„æ¨¡å‹: {config.EMBEDDING_MODEL_NAME}")
        
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("ğŸ“‹ æµ‹è¯•RAGç³»ç»Ÿæ¨¡å‹åŠ è½½...")
        rag = RAGSystem(config)
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        success = rag.initialize()
        if success:
            print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
            print(f"âœ… ä½¿ç”¨æ¨¡å‹: {config.EMBEDDING_MODEL_NAME}")
            
            # æµ‹è¯•ç®€å•çš„åµŒå…¥ç”Ÿæˆ
            if hasattr(rag, 'embedding_model') and rag.embedding_model:
                test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
                embedding = rag.embedding_model.encode([test_text])
                print(f"âœ… åµŒå…¥ç”Ÿæˆæµ‹è¯•æˆåŠŸï¼Œç»´åº¦: {embedding.shape[1]}")
            
            return True
        else:
            print("âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def manual_download_guide():
    """æä¾›æ‰‹åŠ¨ä¸‹è½½æŒ‡å—"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ‰‹åŠ¨ä¸‹è½½æŒ‡å—ï¼ˆå¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼‰:")
    print("=" * 60)
    print("1. è®¿é—®: https://modelscope.cn/models/AI-ModelScope/m3e-base")
    print("2. ç‚¹å‡»'Files and versions'æ ‡ç­¾")
    print("3. ä¸‹è½½ä»¥ä¸‹å…³é”®æ–‡ä»¶:")
    print("   - config.json")
    print("   - pytorch_model.bin")
    print("   - sentence_bert_config.json")
    print("   - tokenizer.json")
    print("   - tokenizer_config.json")
    print("   - vocab.txt")
    print("4. åˆ›å»ºç›®å½•: models/AI-ModelScope/m3e-base/")
    print("5. å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•")
    print("=" * 60)

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ M3E-Base æ¨¡å‹ä¸‹è½½å™¨ (ModelScope)")
    print("ğŸŒ æ¨¡å‹åœ°å€: https://modelscope.cn/models/AI-ModelScope/m3e-base")
    print("=" * 60)
    
    # ä¸‹è½½æ¨¡å‹
    model_dir = download_m3e_model()
    
    if model_dir:
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        test_success = test_model_loading()
        
        if test_success:
            # æ›´æ–°é…ç½®æ–‡ä»¶
            config_success = update_config()
            
            if config_success:
                # æµ‹è¯•RAGé›†æˆ
                test_rag_integration()
    else:
        # æä¾›æ‰‹åŠ¨ä¸‹è½½æŒ‡å—
        manual_download_guide()
    
    print("\n" + "=" * 60)
    print("ğŸ“ M3E-Baseæ¨¡å‹ç‰¹ç‚¹:")
    print("1. ğŸ‡¨ğŸ‡³ ä¸“é—¨ä¸ºä¸­æ–‡ä¼˜åŒ–")
    print("2. ğŸ”Œ æ”¯æŒç¦»çº¿æ¨¡å¼")
    print("3. ğŸ’¾ é€‚åˆ16Gå†…å­˜ç¯å¢ƒ")
    print("4. ğŸ¯ 768ç»´é«˜ç²¾åº¦åµŒå…¥")
    print("5. ğŸš€ åœ¨RAGç³»ç»Ÿä¸­è¡¨ç°ä¼˜å¼‚")
    print("6. ğŸ“š æ”¯æŒå¤šç§æ–‡æœ¬ä»»åŠ¡")
    print("\nğŸ“ æ¨¡å‹æ–‡ä»¶ä½ç½®: models/AI-ModelScope/m3e-base/")
    print("âš™ï¸ é…ç½®æ–‡ä»¶: src/config.py")
    print("=" * 60) 